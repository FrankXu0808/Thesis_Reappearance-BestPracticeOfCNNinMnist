{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import cv2\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import mnist # 导入 pytorch 内置的 mnist 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Elastic_transform(image, alpha, sigma):\n",
    "    shape = image.shape\n",
    "    shape_size = shape[:2]\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dz = np.zeros_like(dx)\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
    "\n",
    "    return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_transform(image, alpha, sigma, random_state=None):\n",
    "    \"\"\"Elastic deformation of images as described in [Simard2003]_.\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "       Proc. of the International Conference on Document Analysis and\n",
    "       Recognition, 2003.\n",
    "    \"\"\"\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "\n",
    "    shape = image.shape\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dz = np.zeros_like(dx)\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]))\n",
    "    print(x.shape)\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
    " \n",
    "    distored_image = map_coordinates(image, indices,order=1, mode='reflect')\n",
    "    return distored_image.reshape(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic transform\n",
    "def elastic_transformations(alpha, sigma, rng=np.random.RandomState(42), \n",
    "                            interpolation_order=1):\n",
    "    \"\"\"Returns a function to elastically transform multiple images.\"\"\"\n",
    "    def _elastic_transform_2D(images):\n",
    "        \"\"\"`images` is a numpy array of shape (K, M, N) of K images of size M*N.\"\"\"\n",
    "        # Take measurements\n",
    "        image_shape = images[0].shape\n",
    "        # Make random fields\n",
    "        dx = rng.uniform(-1, 1, image_shape) * alpha\n",
    "        dy = rng.uniform(-1, 1, image_shape) * alpha\n",
    "        # Smooth dx and dy\n",
    "        sdx = gaussian_filter(dx, sigma=sigma, mode='reflect')\n",
    "        sdy = gaussian_filter(dy, sigma=sigma, mode='reflect')\n",
    "        # Make meshgrid\n",
    "        x, y = np.meshgrid(np.arange(image_shape[1]), np.arange(image_shape[0]))\n",
    "        # Distort meshgrid indices\n",
    "        distorted_indices = (y + sdy).reshape(-1, 1), \\\n",
    "                            (x + sdx).reshape(-1, 1)\n",
    "        # Map cooordinates from image to distorted index set\n",
    "        transformed_images = [map_coordinates(image, distorted_indices, mode='reflect',\n",
    "                                              order=interpolation_order).reshape(image_shape)\n",
    "                              for image in images]\n",
    "        return transformed_images\n",
    "    return _elastic_transform_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用内置函数下载 mnist 数据集\n",
    "train_set = mnist.MNIST('./data', train=True, download=True)\n",
    "test_set = mnist.MNIST('./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1A8CAB38>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_data, a_label = train_set[1]\n",
    "a_data\n",
    "#plt.imshow(a_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "def data_tf(x):\n",
    "    x = np.array(x, dtype='float32') / 255\n",
    "    x = (x - 0.5) / 0.5 # 标准化，这个技巧之后会讲到\n",
    "    x = x.reshape(1,28,28)\n",
    "    x = torch.from_numpy(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "train_set = mnist.MNIST('./data', train=True, transform=data_tf, download=True) # 重新载入数据集，申明定义的数据变换\n",
    "test_set = mnist.MNIST('./data', train=False, transform=data_tf, download=True)\n",
    "\n",
    "a, a_label = train_set[0]\n",
    "print(a.shape)\n",
    "print(a_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: <function data_tf at 0x000000001DE1F400>\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: <function data_tf at 0x000000001DE1F400>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# 使用 pytorch 自带的 DataLoader 定义一个数据迭代器\n",
    "train_data = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(test_set, batch_size=128, shuffle=False)\n",
    "print(train_data.dataset)\n",
    "print(test_data.dataset)\n",
    "a, a_label = next(iter(train_data))\n",
    "# 打印出一个批次的数据大小\n",
    "print(a.shape)\n",
    "print(a_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "def Random_affine(image,alpha_affine,random_state=None):\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "    shape = image.shape\n",
    "    shape_size = shape[:2]\n",
    "    # Random affine\n",
    "    center_square = np.float32(shape_size) // 2\n",
    "    square_size = min(shape_size) // 3\n",
    "    pts1 = np.float32([center_square + square_size, \n",
    "                       [center_square[0]+square_size, center_square[1]-square_size],\n",
    "                       center_square - square_size])\n",
    "    pts2 = pts1 + random_state.uniform(-alpha_affine,\n",
    "                                       alpha_affine, size=pts1.shape).astype(np.float32)\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "\n",
    "    image = cupy.asnumpy(image)\n",
    "    image = cv2.warpAffine(image,M,shape_size[::-1],borderValue=-1)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x50a5828>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_data, a_label = train_set[2]\n",
    "a_data=np.reshape(a_data,(28,28))\n",
    "a_data=Random_affine(a_data,4)\n",
    "print(a_data.shape)\n",
    "\n",
    "plt.imshow(a_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x51362b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b_data, b_label = train_set[2]\n",
    "b_data.shape\n",
    "b_data=np.reshape(b_data,(28,28))\n",
    "b_data\n",
    "plt.imshow(b_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x519c128>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_data, a_label = train_set[2]\n",
    "a_data\n",
    "k=elastic_transformations(34,4)\n",
    "a_data=k(a_data)\n",
    "#a_data=elastic_transform(a_data,34,4)\n",
    "a_data=np.array(a_data, dtype='float32')\n",
    "print(a_data.shape)\n",
    "\n",
    "a_data=np.reshape(a_data,(28,28))\n",
    "\n",
    "\n",
    "plt.imshow(a_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConv,self).__init__()\n",
    "        self.layer1=nn.Sequential(nn.Conv2d(1,5,kernel_size=5,stride=(2,2),padding=(1,1)),nn.BatchNorm2d(5),nn.Sigmoid())#5 13 13\n",
    "        self.layer2=nn.Sequential(nn.Conv2d(5,50,kernel_size=5,stride=(2,2)),nn.BatchNorm2d(50),nn.Sigmoid()) #50 5 5\n",
    "       \n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(5*5*50,100),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(100,10),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x =  self.layer1(x)\n",
    "        x =  self.layer2(x)\n",
    "        x =  x.view(x.size(0),-1)#展平\n",
    "        x =  self.fc(x)\n",
    "        return  x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleConv(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 5, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Sigmoid()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(5, 50, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Sigmoid()\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1250, out_features=100, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(torch.cuda.is_available())\n",
    "if(torch.cuda.is_available()):\n",
    "    net=SimpleConv().cuda()\n",
    "    print(\"cuda\")\n",
    "else:\n",
    "    net=SimpleConv()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "# 定义 loss 函数\n",
    "loss_func  = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), 0.005) # 使用随机梯度下降，学习率 0.1\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def get_acc(output, label):\n",
    "    total = output.shape[0]\n",
    "    _, pred_label = output.max(1)\n",
    "    num_correct = (pred_label == label).sum().item()\n",
    "    return num_correct / total\n",
    "\n",
    "\n",
    "def train(net, train_data, valid_data, num_epochs, optimizer, criterion,scheduler):\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.cuda()\n",
    "    prev_time = datetime.now()\n",
    "    for epoch in range(num_epochs):\n",
    "        scheduler.step()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        net = net.train()\n",
    "        for im, label in train_data:\n",
    "          new_data=[]\n",
    "          train_list=[]\n",
    "          train_list.append(im)\n",
    "          '''\n",
    "          for i in range(im.shape[0]):\n",
    "              a_data=np.reshape(im[i],(28,28))\n",
    "              affine=Random_affine(a_data,4)\n",
    "              affine=np.reshape(affine,(1,28,28))\n",
    "              new_data.append(affine)\n",
    "          new_data=np.array(new_data)\n",
    "          new_data=torch.from_numpy(new_data)\n",
    "          #print(\"$$$\",im.dtype,new_data.dtype)\n",
    "          '''   \n",
    "          for i in range(im.shape[0]):             \n",
    "              ela_temp=elastic_transformations(34,4)\n",
    "              elastic=ela_temp(im[i])\n",
    "              elastic=np.array(elastic, dtype='float32')\n",
    "              new_data.append(elastic)\n",
    "                \n",
    "                \n",
    "          new_data=np.array(new_data)\n",
    "          new_data=torch.from_numpy(new_data)\n",
    "          train_list.append(new_data)\n",
    "\n",
    "          for ims in train_list:\n",
    "            if torch.cuda.is_available():\n",
    "                ims = Variable(ims.cuda())  # (bs, 3, h, w)\n",
    "                label = Variable(label.cuda())  # (bs, h, w)\n",
    "            else:\n",
    "                ims = Variable(ims)\n",
    "                label = Variable(label)\n",
    "            # forward\n",
    "            #print(ims.shape)\n",
    "            output = net(ims)\n",
    "            loss = criterion(output, label)\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_acc += get_acc(output, label)\n",
    "\n",
    "        cur_time = datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        if valid_data is not None:\n",
    "            valid_loss = 0\n",
    "            valid_acc = 0\n",
    "            net = net.eval()\n",
    "            for im, label in valid_data:\n",
    "                if torch.cuda.is_available():\n",
    "                    im = Variable(im.cuda(), volatile=True)\n",
    "                    label = Variable(label.cuda(), volatile=True)\n",
    "                else:\n",
    "                    im = Variable(im, volatile=True)\n",
    "                    label = Variable(label, volatile=True)\n",
    "                output = net(im)\n",
    "                loss = criterion(output, label)\n",
    "                valid_loss += loss.item()\n",
    "                valid_acc += get_acc(output, label)\n",
    "            epoch_str = (\n",
    "                \"Epoch %d. Train Loss: %f, Train Acc: %f, Valid Loss: %f, Valid Acc: %f, \"\n",
    "                % (epoch, train_loss / len(train_data),\n",
    "                   train_acc / len(train_data), valid_loss / len(valid_data),\n",
    "                   valid_acc / len(valid_data)))\n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Train Loss: %f, Train Acc: %f, \" %\n",
    "                         (epoch, train_loss / len(train_data),\n",
    "                          train_acc / len(train_data)))\n",
    "        prev_time = cur_time\n",
    "        print(epoch_str + time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将预训练模型载入\n",
    "net.load_state_dict(torch.load('./elastic.pth',map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 0.161181, Train Acc: 1.949993, Valid Loss: 0.027298, Valid Acc: 0.990902, Time 00:02:12\n",
      "Epoch 1. Train Loss: 0.159656, Train Acc: 1.950560, Valid Loss: 0.028896, Valid Acc: 0.990605, Time 00:02:10\n",
      "Epoch 2. Train Loss: 0.164541, Train Acc: 1.949544, Valid Loss: 0.026324, Valid Acc: 0.991199, Time 00:02:12\n",
      "Epoch 3. Train Loss: 0.165839, Train Acc: 1.950227, Valid Loss: 0.029156, Valid Acc: 0.990704, Time 00:02:14\n",
      "Epoch 4. Train Loss: 0.164880, Train Acc: 1.949044, Valid Loss: 0.028317, Valid Acc: 0.991001, Time 00:02:13\n",
      "Epoch 5. Train Loss: 0.162924, Train Acc: 1.949544, Valid Loss: 0.027917, Valid Acc: 0.990605, Time 00:02:10\n",
      "Epoch 6. Train Loss: 0.163674, Train Acc: 1.949344, Valid Loss: 0.030294, Valid Acc: 0.989715, Time 00:02:11\n",
      "Epoch 7. Train Loss: 0.161080, Train Acc: 1.950876, Valid Loss: 0.031469, Valid Acc: 0.990012, Time 00:02:10\n",
      "Epoch 8. Train Loss: 0.164298, Train Acc: 1.948844, Valid Loss: 0.029004, Valid Acc: 0.990902, Time 00:02:12\n",
      "Epoch 9. Train Loss: 0.162810, Train Acc: 1.950393, Valid Loss: 0.027772, Valid Acc: 0.990704, Time 00:02:15\n",
      "Epoch 10. Train Loss: 0.161914, Train Acc: 1.950676, Valid Loss: 0.028992, Valid Acc: 0.991001, Time 00:02:12\n",
      "Epoch 11. Train Loss: 0.161980, Train Acc: 1.950426, Valid Loss: 0.028676, Valid Acc: 0.990803, Time 00:02:02\n",
      "Epoch 12. Train Loss: 0.162473, Train Acc: 1.949377, Valid Loss: 0.027197, Valid Acc: 0.990605, Time 00:02:01\n",
      "Epoch 13. Train Loss: 0.162902, Train Acc: 1.950027, Valid Loss: 0.027467, Valid Acc: 0.991199, Time 00:02:01\n",
      "Epoch 14. Train Loss: 0.161833, Train Acc: 1.950576, Valid Loss: 0.028198, Valid Acc: 0.990803, Time 00:02:01\n",
      "Epoch 15. Train Loss: 0.161126, Train Acc: 1.949793, Valid Loss: 0.029756, Valid Acc: 0.990111, Time 00:02:01\n",
      "Epoch 16. Train Loss: 0.159698, Train Acc: 1.952109, Valid Loss: 0.025934, Valid Acc: 0.991001, Time 00:02:01\n",
      "Epoch 17. Train Loss: 0.160951, Train Acc: 1.950810, Valid Loss: 0.027868, Valid Acc: 0.990605, Time 00:02:01\n",
      "Epoch 18. Train Loss: 0.158548, Train Acc: 1.951909, Valid Loss: 0.027303, Valid Acc: 0.991100, Time 00:02:00\n",
      "Epoch 19. Train Loss: 0.163727, Train Acc: 1.949444, Valid Loss: 0.026371, Valid Acc: 0.991297, Time 00:02:00\n",
      "Epoch 20. Train Loss: 0.160502, Train Acc: 1.950143, Valid Loss: 0.026970, Valid Acc: 0.991001, Time 00:02:00\n",
      "Epoch 21. Train Loss: 0.159792, Train Acc: 1.951426, Valid Loss: 0.028764, Valid Acc: 0.990506, Time 00:02:00\n",
      "Epoch 22. Train Loss: 0.161411, Train Acc: 1.950510, Valid Loss: 0.026923, Valid Acc: 0.991100, Time 00:02:04\n",
      "Epoch 23. Train Loss: 0.163530, Train Acc: 1.949394, Valid Loss: 0.027322, Valid Acc: 0.990704, Time 00:02:11\n",
      "Epoch 24. Train Loss: 0.158213, Train Acc: 1.951109, Valid Loss: 0.028889, Valid Acc: 0.990407, Time 00:02:04\n",
      "Epoch 25. Train Loss: 0.164239, Train Acc: 1.949910, Valid Loss: 0.026358, Valid Acc: 0.991297, Time 00:02:08\n",
      "Epoch 26. Train Loss: 0.163890, Train Acc: 1.949044, Valid Loss: 0.029321, Valid Acc: 0.991001, Time 00:02:06\n",
      "Epoch 27. Train Loss: 0.160749, Train Acc: 1.951009, Valid Loss: 0.027376, Valid Acc: 0.991297, Time 00:02:12\n",
      "Epoch 28. Train Loss: 0.164698, Train Acc: 1.949110, Valid Loss: 0.029622, Valid Acc: 0.990506, Time 00:02:18\n",
      "Epoch 29. Train Loss: 0.161672, Train Acc: 1.950626, Valid Loss: 0.027286, Valid Acc: 0.991297, Time 00:02:17\n",
      "Epoch 30. Train Loss: 0.161786, Train Acc: 1.950393, Valid Loss: 0.027948, Valid Acc: 0.990803, Time 00:02:14\n",
      "Epoch 31. Train Loss: 0.160235, Train Acc: 1.951409, Valid Loss: 0.028917, Valid Acc: 0.990309, Time 00:02:20\n",
      "Epoch 32. Train Loss: 0.160464, Train Acc: 1.950476, Valid Loss: 0.026880, Valid Acc: 0.991594, Time 00:02:10\n",
      "Epoch 33. Train Loss: 0.157662, Train Acc: 1.951509, Valid Loss: 0.028019, Valid Acc: 0.990506, Time 00:02:11\n",
      "Epoch 34. Train Loss: 0.159029, Train Acc: 1.951076, Valid Loss: 0.026033, Valid Acc: 0.991199, Time 00:02:10\n",
      "Epoch 35. Train Loss: 0.159896, Train Acc: 1.951193, Valid Loss: 0.025592, Valid Acc: 0.991199, Time 00:02:12\n",
      "Epoch 36. Train Loss: 0.158547, Train Acc: 1.950476, Valid Loss: 0.030413, Valid Acc: 0.989814, Time 00:02:13\n",
      "Epoch 37. Train Loss: 0.159953, Train Acc: 1.951243, Valid Loss: 0.026979, Valid Acc: 0.990605, Time 00:02:10\n",
      "Epoch 38. Train Loss: 0.160139, Train Acc: 1.950976, Valid Loss: 0.026551, Valid Acc: 0.991001, Time 00:02:14\n",
      "Epoch 39. Train Loss: 0.161464, Train Acc: 1.950143, Valid Loss: 0.026897, Valid Acc: 0.991297, Time 00:02:17\n",
      "Epoch 40. Train Loss: 0.159613, Train Acc: 1.951159, Valid Loss: 0.029932, Valid Acc: 0.990309, Time 00:02:12\n",
      "Epoch 41. Train Loss: 0.159025, Train Acc: 1.951942, Valid Loss: 0.027278, Valid Acc: 0.990506, Time 00:02:17\n",
      "Epoch 42. Train Loss: 0.158768, Train Acc: 1.950626, Valid Loss: 0.027055, Valid Acc: 0.991001, Time 00:02:17\n",
      "Epoch 43. Train Loss: 0.161069, Train Acc: 1.950326, Valid Loss: 0.025477, Valid Acc: 0.991495, Time 00:02:15\n",
      "Epoch 44. Train Loss: 0.157286, Train Acc: 1.951726, Valid Loss: 0.025694, Valid Acc: 0.991594, Time 00:02:20\n",
      "Epoch 45. Train Loss: 0.158436, Train Acc: 1.951309, Valid Loss: 0.027085, Valid Acc: 0.990704, Time 00:02:29\n",
      "Epoch 46. Train Loss: 0.158123, Train Acc: 1.950959, Valid Loss: 0.025809, Valid Acc: 0.991199, Time 00:02:20\n",
      "Epoch 47. Train Loss: 0.159026, Train Acc: 1.951009, Valid Loss: 0.026953, Valid Acc: 0.991199, Time 00:02:16\n",
      "Epoch 48. Train Loss: 0.157954, Train Acc: 1.951876, Valid Loss: 0.026128, Valid Acc: 0.991297, Time 00:02:17\n",
      "Epoch 49. Train Loss: 0.158189, Train Acc: 1.951709, Valid Loss: 0.026336, Valid Acc: 0.991001, Time 00:02:20\n",
      "Epoch 50. Train Loss: 0.155212, Train Acc: 1.951476, Valid Loss: 0.026741, Valid Acc: 0.990902, Time 00:02:16\n",
      "Epoch 51. Train Loss: 0.157437, Train Acc: 1.951759, Valid Loss: 0.025931, Valid Acc: 0.991001, Time 00:02:16\n",
      "Epoch 52. Train Loss: 0.157175, Train Acc: 1.951926, Valid Loss: 0.025895, Valid Acc: 0.991100, Time 00:02:18\n",
      "Epoch 53. Train Loss: 0.158627, Train Acc: 1.952242, Valid Loss: 0.026296, Valid Acc: 0.991396, Time 00:02:21\n",
      "Epoch 54. Train Loss: 0.159810, Train Acc: 1.950959, Valid Loss: 0.025874, Valid Acc: 0.991199, Time 00:02:18\n",
      "Epoch 55. Train Loss: 0.155922, Train Acc: 1.951926, Valid Loss: 0.026474, Valid Acc: 0.990704, Time 00:02:19\n",
      "Epoch 56. Train Loss: 0.155044, Train Acc: 1.952442, Valid Loss: 0.025858, Valid Acc: 0.991693, Time 00:02:16\n",
      "Epoch 57. Train Loss: 0.155557, Train Acc: 1.952092, Valid Loss: 0.026329, Valid Acc: 0.991199, Time 00:02:31\n",
      "Epoch 58. Train Loss: 0.156632, Train Acc: 1.951226, Valid Loss: 0.025936, Valid Acc: 0.991100, Time 00:02:36\n",
      "Epoch 59. Train Loss: 0.158330, Train Acc: 1.951326, Valid Loss: 0.026251, Valid Acc: 0.991001, Time 00:02:34\n",
      "Epoch 60. Train Loss: 0.157507, Train Acc: 1.952625, Valid Loss: 0.026353, Valid Acc: 0.990902, Time 00:02:38\n",
      "Epoch 61. Train Loss: 0.153271, Train Acc: 1.952825, Valid Loss: 0.026381, Valid Acc: 0.990902, Time 00:02:34\n",
      "Epoch 62. Train Loss: 0.158286, Train Acc: 1.951493, Valid Loss: 0.026698, Valid Acc: 0.991001, Time 00:02:34\n",
      "Epoch 63. Train Loss: 0.156206, Train Acc: 1.951759, Valid Loss: 0.025857, Valid Acc: 0.991199, Time 00:02:36\n",
      "Epoch 64. Train Loss: 0.160416, Train Acc: 1.951226, Valid Loss: 0.026122, Valid Acc: 0.990902, Time 00:02:40\n",
      "Epoch 65. Train Loss: 0.159486, Train Acc: 1.951409, Valid Loss: 0.026079, Valid Acc: 0.990704, Time 00:02:34\n",
      "Epoch 66. Train Loss: 0.158865, Train Acc: 1.951876, Valid Loss: 0.025914, Valid Acc: 0.991594, Time 00:02:36\n",
      "Epoch 67. Train Loss: 0.154277, Train Acc: 1.953475, Valid Loss: 0.026051, Valid Acc: 0.991001, Time 00:02:36\n",
      "Epoch 68. Train Loss: 0.157084, Train Acc: 1.951742, Valid Loss: 0.026252, Valid Acc: 0.991001, Time 00:02:35\n",
      "Epoch 69. Train Loss: 0.155830, Train Acc: 1.951909, Valid Loss: 0.026271, Valid Acc: 0.990902, Time 00:02:35\n",
      "Epoch 70. Train Loss: 0.156478, Train Acc: 1.952958, Valid Loss: 0.026075, Valid Acc: 0.991297, Time 00:02:33\n",
      "Epoch 71. Train Loss: 0.153753, Train Acc: 1.952542, Valid Loss: 0.026506, Valid Acc: 0.991001, Time 00:02:46\n",
      "Epoch 72. Train Loss: 0.156800, Train Acc: 1.951959, Valid Loss: 0.025758, Valid Acc: 0.990902, Time 00:02:40\n",
      "Epoch 73. Train Loss: 0.155058, Train Acc: 1.951892, Valid Loss: 0.025821, Valid Acc: 0.991297, Time 00:02:36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74. Train Loss: 0.155183, Train Acc: 1.952475, Valid Loss: 0.025901, Valid Acc: 0.990902, Time 00:02:40\n",
      "Epoch 75. Train Loss: 0.158780, Train Acc: 1.952242, Valid Loss: 0.026729, Valid Acc: 0.990902, Time 00:02:37\n",
      "Epoch 76. Train Loss: 0.154239, Train Acc: 1.952942, Valid Loss: 0.027021, Valid Acc: 0.991100, Time 00:02:38\n",
      "Epoch 77. Train Loss: 0.155024, Train Acc: 1.952042, Valid Loss: 0.026722, Valid Acc: 0.990902, Time 00:02:36\n",
      "Epoch 78. Train Loss: 0.155401, Train Acc: 1.952659, Valid Loss: 0.026133, Valid Acc: 0.991297, Time 00:02:36\n",
      "Epoch 79. Train Loss: 0.155012, Train Acc: 1.952492, Valid Loss: 0.026405, Valid Acc: 0.990902, Time 00:02:38\n",
      "Epoch 80. Train Loss: 0.155190, Train Acc: 1.952709, Valid Loss: 0.025924, Valid Acc: 0.991297, Time 00:02:24\n",
      "Epoch 81. Train Loss: 0.156194, Train Acc: 1.952725, Valid Loss: 0.025952, Valid Acc: 0.991001, Time 00:02:17\n",
      "Epoch 82. Train Loss: 0.157837, Train Acc: 1.951792, Valid Loss: 0.026236, Valid Acc: 0.991100, Time 00:02:19\n",
      "Epoch 83. Train Loss: 0.155194, Train Acc: 1.951742, Valid Loss: 0.025886, Valid Acc: 0.991297, Time 00:02:19\n",
      "Epoch 84. Train Loss: 0.157375, Train Acc: 1.951626, Valid Loss: 0.026214, Valid Acc: 0.991001, Time 00:02:19\n",
      "Epoch 85. Train Loss: 0.158381, Train Acc: 1.951126, Valid Loss: 0.026117, Valid Acc: 0.991297, Time 00:02:20\n",
      "Epoch 86. Train Loss: 0.155864, Train Acc: 1.952009, Valid Loss: 0.025848, Valid Acc: 0.991100, Time 00:02:23\n",
      "Epoch 87. Train Loss: 0.158178, Train Acc: 1.951076, Valid Loss: 0.025997, Valid Acc: 0.991001, Time 00:02:26\n",
      "Epoch 88. Train Loss: 0.154332, Train Acc: 1.953042, Valid Loss: 0.025321, Valid Acc: 0.991495, Time 00:02:20\n",
      "Epoch 89. Train Loss: 0.155807, Train Acc: 1.952325, Valid Loss: 0.025786, Valid Acc: 0.991100, Time 00:02:22\n",
      "Epoch 90. Train Loss: 0.155372, Train Acc: 1.952809, Valid Loss: 0.025310, Valid Acc: 0.991396, Time 00:02:23\n",
      "Epoch 91. Train Loss: 0.155929, Train Acc: 1.952359, Valid Loss: 0.026250, Valid Acc: 0.991100, Time 00:02:12\n",
      "Epoch 92. Train Loss: 0.156335, Train Acc: 1.952492, Valid Loss: 0.026031, Valid Acc: 0.990803, Time 00:02:13\n",
      "Epoch 93. Train Loss: 0.155694, Train Acc: 1.952409, Valid Loss: 0.025775, Valid Acc: 0.991001, Time 00:02:23\n",
      "Epoch 94. Train Loss: 0.154309, Train Acc: 1.952009, Valid Loss: 0.025971, Valid Acc: 0.991297, Time 00:02:24\n",
      "Epoch 95. Train Loss: 0.154725, Train Acc: 1.953058, Valid Loss: 0.025713, Valid Acc: 0.991297, Time 00:02:18\n",
      "Epoch 96. Train Loss: 0.152891, Train Acc: 1.953242, Valid Loss: 0.026084, Valid Acc: 0.990902, Time 00:02:20\n",
      "Epoch 97. Train Loss: 0.156347, Train Acc: 1.952908, Valid Loss: 0.025506, Valid Acc: 0.991199, Time 00:02:18\n",
      "Epoch 98. Train Loss: 0.154597, Train Acc: 1.952559, Valid Loss: 0.025995, Valid Acc: 0.991100, Time 00:02:21\n",
      "Epoch 99. Train Loss: 0.154505, Train Acc: 1.953342, Valid Loss: 0.025816, Valid Acc: 0.991297, Time 00:02:24\n",
      "Epoch 100. Train Loss: 0.154994, Train Acc: 1.953342, Valid Loss: 0.026382, Valid Acc: 0.991100, Time 00:02:23\n",
      "Epoch 101. Train Loss: 0.156742, Train Acc: 1.950876, Valid Loss: 0.026107, Valid Acc: 0.991199, Time 00:02:20\n",
      "Epoch 102. Train Loss: 0.155048, Train Acc: 1.952442, Valid Loss: 0.026579, Valid Acc: 0.991199, Time 00:02:16\n",
      "Epoch 103. Train Loss: 0.157150, Train Acc: 1.951326, Valid Loss: 0.026110, Valid Acc: 0.990902, Time 00:02:34\n",
      "Epoch 104. Train Loss: 0.157337, Train Acc: 1.953275, Valid Loss: 0.025621, Valid Acc: 0.991297, Time 00:02:27\n",
      "Epoch 105. Train Loss: 0.154863, Train Acc: 1.952375, Valid Loss: 0.026089, Valid Acc: 0.991100, Time 00:02:29\n",
      "Epoch 106. Train Loss: 0.156424, Train Acc: 1.951692, Valid Loss: 0.026146, Valid Acc: 0.990902, Time 00:02:22\n",
      "Epoch 107. Train Loss: 0.157724, Train Acc: 1.951509, Valid Loss: 0.026313, Valid Acc: 0.991297, Time 00:02:16\n",
      "Epoch 108. Train Loss: 0.154164, Train Acc: 1.952525, Valid Loss: 0.026070, Valid Acc: 0.991396, Time 00:02:15\n",
      "Epoch 109. Train Loss: 0.156051, Train Acc: 1.951459, Valid Loss: 0.025527, Valid Acc: 0.991693, Time 00:02:13\n",
      "Epoch 110. Train Loss: 0.154710, Train Acc: 1.952792, Valid Loss: 0.025496, Valid Acc: 0.991297, Time 00:02:13\n",
      "Epoch 111. Train Loss: 0.155347, Train Acc: 1.952425, Valid Loss: 0.025639, Valid Acc: 0.991396, Time 00:02:20\n",
      "Epoch 112. Train Loss: 0.155301, Train Acc: 1.953108, Valid Loss: 0.025655, Valid Acc: 0.991495, Time 00:02:17\n",
      "Epoch 113. Train Loss: 0.153066, Train Acc: 1.953875, Valid Loss: 0.026525, Valid Acc: 0.990704, Time 00:02:35\n",
      "Epoch 114. Train Loss: 0.153457, Train Acc: 1.952642, Valid Loss: 0.025706, Valid Acc: 0.991594, Time 00:02:21\n",
      "Epoch 115. Train Loss: 0.157543, Train Acc: 1.951709, Valid Loss: 0.026180, Valid Acc: 0.990902, Time 00:02:14\n",
      "Epoch 116. Train Loss: 0.157869, Train Acc: 1.952659, Valid Loss: 0.025930, Valid Acc: 0.991001, Time 00:02:15\n",
      "Epoch 117. Train Loss: 0.156720, Train Acc: 1.951543, Valid Loss: 0.025988, Valid Acc: 0.991297, Time 00:02:22\n",
      "Epoch 118. Train Loss: 0.155539, Train Acc: 1.951892, Valid Loss: 0.025461, Valid Acc: 0.991199, Time 00:02:21\n",
      "Epoch 119. Train Loss: 0.156212, Train Acc: 1.951909, Valid Loss: 0.025539, Valid Acc: 0.991396, Time 00:02:34\n",
      "Epoch 120. Train Loss: 0.154379, Train Acc: 1.952325, Valid Loss: 0.025703, Valid Acc: 0.991396, Time 00:02:19\n",
      "Epoch 121. Train Loss: 0.151346, Train Acc: 1.953491, Valid Loss: 0.025844, Valid Acc: 0.991100, Time 00:02:17\n",
      "Epoch 122. Train Loss: 0.154806, Train Acc: 1.952259, Valid Loss: 0.025538, Valid Acc: 0.991001, Time 00:02:47\n",
      "Epoch 123. Train Loss: 0.153421, Train Acc: 1.952925, Valid Loss: 0.026263, Valid Acc: 0.991100, Time 00:02:32\n",
      "Epoch 124. Train Loss: 0.153197, Train Acc: 1.953558, Valid Loss: 0.027092, Valid Acc: 0.991199, Time 00:02:41\n",
      "Epoch 125. Train Loss: 0.152484, Train Acc: 1.953242, Valid Loss: 0.025409, Valid Acc: 0.991297, Time 00:02:57\n",
      "Epoch 126. Train Loss: 0.154008, Train Acc: 1.952759, Valid Loss: 0.026158, Valid Acc: 0.991001, Time 00:03:16\n",
      "Epoch 127. Train Loss: 0.153844, Train Acc: 1.952675, Valid Loss: 0.026052, Valid Acc: 0.991199, Time 00:03:18\n",
      "Epoch 128. Train Loss: 0.153854, Train Acc: 1.953475, Valid Loss: 0.025317, Valid Acc: 0.991297, Time 01:36:39\n",
      "Epoch 129. Train Loss: 0.158936, Train Acc: 1.950760, Valid Loss: 0.025539, Valid Acc: 0.991495, Time 00:02:16\n",
      "Epoch 130. Train Loss: 0.153593, Train Acc: 1.952925, Valid Loss: 0.025489, Valid Acc: 0.991199, Time 00:02:16\n",
      "Epoch 131. Train Loss: 0.152689, Train Acc: 1.952908, Valid Loss: 0.025916, Valid Acc: 0.991693, Time 00:02:15\n",
      "Epoch 132. Train Loss: 0.153447, Train Acc: 1.952409, Valid Loss: 0.025942, Valid Acc: 0.991297, Time 00:02:17\n",
      "Epoch 133. Train Loss: 0.156703, Train Acc: 1.952242, Valid Loss: 0.025712, Valid Acc: 0.991594, Time 00:02:16\n",
      "Epoch 134. Train Loss: 0.156443, Train Acc: 1.951909, Valid Loss: 0.026132, Valid Acc: 0.990803, Time 00:02:16\n",
      "Epoch 135. Train Loss: 0.156480, Train Acc: 1.953175, Valid Loss: 0.025618, Valid Acc: 0.991001, Time 00:02:16\n",
      "Epoch 136. Train Loss: 0.152938, Train Acc: 1.952825, Valid Loss: 0.026055, Valid Acc: 0.991001, Time 00:02:16\n",
      "Epoch 137. Train Loss: 0.155363, Train Acc: 1.952192, Valid Loss: 0.025927, Valid Acc: 0.991001, Time 00:02:16\n",
      "Epoch 138. Train Loss: 0.156250, Train Acc: 1.952775, Valid Loss: 0.025763, Valid Acc: 0.991199, Time 00:02:16\n",
      "Epoch 139. Train Loss: 0.153510, Train Acc: 1.952725, Valid Loss: 0.026379, Valid Acc: 0.991199, Time 00:02:16\n",
      "Epoch 140. Train Loss: 0.154672, Train Acc: 1.952825, Valid Loss: 0.025192, Valid Acc: 0.991495, Time 00:02:16\n",
      "Epoch 141. Train Loss: 0.154932, Train Acc: 1.952392, Valid Loss: 0.026159, Valid Acc: 0.991199, Time 00:02:15\n",
      "Epoch 142. Train Loss: 0.154968, Train Acc: 1.952442, Valid Loss: 0.026210, Valid Acc: 0.990902, Time 00:02:16\n",
      "Epoch 143. Train Loss: 0.157397, Train Acc: 1.952142, Valid Loss: 0.025891, Valid Acc: 0.991297, Time 00:02:16\n",
      "Epoch 144. Train Loss: 0.156012, Train Acc: 1.951376, Valid Loss: 0.026023, Valid Acc: 0.990902, Time 00:02:16\n",
      "Epoch 145. Train Loss: 0.155759, Train Acc: 1.951809, Valid Loss: 0.025714, Valid Acc: 0.991100, Time 00:02:16\n",
      "Epoch 146. Train Loss: 0.155753, Train Acc: 1.953125, Valid Loss: 0.025719, Valid Acc: 0.991297, Time 00:02:15\n",
      "Epoch 147. Train Loss: 0.155084, Train Acc: 1.952159, Valid Loss: 0.026122, Valid Acc: 0.990902, Time 00:02:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148. Train Loss: 0.152773, Train Acc: 1.953242, Valid Loss: 0.025427, Valid Acc: 0.991100, Time 00:02:16\n",
      "Epoch 149. Train Loss: 0.159146, Train Acc: 1.950743, Valid Loss: 0.025952, Valid Acc: 0.990704, Time 00:02:15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train(net, train_data, test_data, 150, optimizer, loss_func,scheduler=scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型\n",
    "model_path='./elastic.pth'\n",
    "torch.save(net.state_dict(),model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
