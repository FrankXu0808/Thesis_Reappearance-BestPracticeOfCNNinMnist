{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import mnist # 导入 pytorch 内置的 mnist 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_affine(image,alpha_affine):\n",
    "    shape = image.shape\n",
    "    shape_size = shape[:2]\n",
    "    # Random affine\n",
    "    center_square = np.float32(shape_size) // 2\n",
    "    square_size = min(shape_size) // 3\n",
    "    pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size], center_square - square_size])\n",
    "    pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "    image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic transform\n",
    "def elastic_transformations(alpha, sigma, rng=np.random.RandomState(42), \n",
    "                            interpolation_order=1):\n",
    "    \"\"\"Returns a function to elastically transform multiple images.\"\"\"\n",
    "    # Good values for:\n",
    "    #   alpha: 2000\n",
    "    #   sigma: between 40 and 60\n",
    "    def _elastic_transform_2D(images):\n",
    "        \"\"\"`images` is a numpy array of shape (K, M, N) of K images of size M*N.\"\"\"\n",
    "        # Take measurements\n",
    "        image_shape = images[0].shape\n",
    "        # Make random fields\n",
    "        dx = rng.uniform(-1, 1, image_shape) * alpha\n",
    "        dy = rng.uniform(-1, 1, image_shape) * alpha\n",
    "        # Smooth dx and dy\n",
    "        sdx = gaussian_filter(dx, sigma=sigma, mode='reflect')\n",
    "        sdy = gaussian_filter(dy, sigma=sigma, mode='reflect')\n",
    "        # Make meshgrid\n",
    "        x, y = np.meshgrid(np.arange(image_shape[1]), np.arange(image_shape[0]))\n",
    "        # Distort meshgrid indices\n",
    "        distorted_indices = (y + sdy).reshape(-1, 1), \\\n",
    "                            (x + sdx).reshape(-1, 1)\n",
    "\n",
    "        # Map cooordinates from image to distorted index set\n",
    "        transformed_images = [map_coordinates(image, distorted_indices, mode='reflect',\n",
    "                                              order=interpolation_order).reshape(image_shape)\n",
    "                              for image in images]\n",
    "        return transformed_images\n",
    "    return _elastic_transform_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用内置函数下载 mnist 数据集\n",
    "train_set = mnist.MNIST('./data', train=True, download=True)\n",
    "test_set = mnist.MNIST('./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tf(x):\n",
    "    x = np.array(x, dtype='float32') / 255\n",
    "    x = (x - 0.5) / 0.5 # 标准化，这个技巧之后会讲到\n",
    "    x = x.reshape((-1,)) # 拉平\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "train_set = mnist.MNIST('./data', train=True, transform=data_tf, download=True) # 重新载入数据集，申明定义的数据变换\n",
    "test_set = mnist.MNIST('./data', train=False, transform=data_tf, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: <function data_tf at 0x000000001A579D90>\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: <function data_tf at 0x000000001A579D90>\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# 使用 pytorch 自带的 DataLoader 定义一个数据迭代器\n",
    "train_data = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(test_set, batch_size=128, shuffle=False)\n",
    "print(train_data.dataset)\n",
    "print(test_data.dataset)\n",
    "a, a_label = next(iter(train_data))\n",
    "# 打印出一个批次的数据大小\n",
    "print(a.shape)\n",
    "print(a_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TwoLayerMlp = nn.Sequential(\n",
    "    nn.Linear(784, 800),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(800, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "# 定义 loss 函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(TwoLayerMlp.parameters(), 0.005) # 使用随机梯度下降，学习率 0.1\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.3)\n",
    "'''\n",
    "plt.figure()\n",
    "x = list(range(100))\n",
    "y = []\n",
    "for epoch in range(100):\n",
    "    scheduler.step()\n",
    "    lr = scheduler.get_lr()\n",
    "    print(epoch, scheduler.get_lr()[0])\n",
    "    y.append(scheduler.get_lr()[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Train Loss: 0.385108, Train Acc: 0.892774, Eval Loss: 0.361761, Eval Acc: 0.899031\n",
      "epoch: 1, Train Loss: 0.375197, Train Acc: 0.894523, Eval Loss: 0.352507, Eval Acc: 0.901305\n",
      "epoch: 2, Train Loss: 0.366696, Train Acc: 0.896255, Eval Loss: 0.345043, Eval Acc: 0.902492\n",
      "epoch: 3, Train Loss: 0.359719, Train Acc: 0.897788, Eval Loss: 0.338679, Eval Acc: 0.903580\n",
      "epoch: 4, Train Loss: 0.353051, Train Acc: 0.898971, Eval Loss: 0.332404, Eval Acc: 0.904074\n"
     ]
    }
   ],
   "source": [
    "# TwoLayerMlp训练\n",
    "losses = []\n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    "\n",
    "for e in range(5):\n",
    "    scheduler.step()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    TwoLayerMlp.train()\n",
    "    for im, label in train_data:\n",
    "        im = Variable(im)\n",
    "        label = Variable(label)\n",
    "        # 前向传播\n",
    "        out = TwoLayerMlp(im)\n",
    "        loss = criterion(out, label)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 记录误差\n",
    "        train_loss += loss.data\n",
    "        # 计算分类的准确率\n",
    "        _, pred = out.max(1)\n",
    "        #print(\"out\",out.max(1))\n",
    "        #print(\"pred\",pred)    \n",
    "        num_correct = (pred == label).sum().data\n",
    "        acc = float(num_correct) / float(im.shape[0])\n",
    "        train_acc += acc\n",
    "        \n",
    "    losses.append(train_loss / len(train_data))\n",
    "    acces.append(train_acc / len(train_data))\n",
    "    # 在测试集上检验效果\n",
    "    eval_loss = 0.0\n",
    "    eval_acc = 0.0\n",
    "    TwoLayerMlp.eval() # 将模型改为预测模式\n",
    "    for im, label in test_data:\n",
    "        im = Variable(im)\n",
    "        label = Variable(label)\n",
    "        out = TwoLayerMlp(im)\n",
    "        loss = criterion(out, label)\n",
    "        # 记录误差\n",
    "        eval_loss += loss.data\n",
    "        # 记录准确率\n",
    "        _, pred = out.max(1)\n",
    "       \n",
    "        num_correct = (pred == label).sum().data\n",
    "        acc = float(num_correct) / float(im.shape[0])\n",
    "        eval_acc += acc\n",
    "        \n",
    "    eval_losses.append(eval_loss / len(test_data))\n",
    "    eval_acces.append(eval_acc / len(test_data))\n",
    "    print('epoch: {}, Train Loss: {:.6f}, Train Acc: {:.6f}, Eval Loss: {:.6f}, Eval Acc: {:.6f}'\n",
    "          .format(e, train_loss / len(train_data), train_acc / len(train_data), \n",
    "                     eval_loss / len(test_data), eval_acc / len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
